{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function \n",
    "\n",
    "def bit_to_list(t, n):\n",
    "    S = [0 for i in range(n)]    \n",
    "    i = -1\n",
    "    while t != 0:\n",
    "        S[i] = t % 2\n",
    "        t = t >> 1\n",
    "        i -= 1\n",
    "    return S\n",
    "bit_to_list(1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# graph representation\n",
    "# build up the graph with weights\n",
    "\n",
    "graph = {\n",
    "    \"s\": {\"0\": lambda x : x, \"1\": lambda x : 2},\n",
    "    \"a\": {\"2\": lambda x : 1, \"4\": lambda x : x},\n",
    "    \"b\": {\"3\": lambda x : 1, \"5\": lambda x : x},\n",
    "    \"c\": {\"6\": lambda x : x},\n",
    "    \"d\": {\"7\": lambda x : 1}\n",
    "}\n",
    "\n",
    "weight = graph[\"s\"]\n",
    "for i in weight.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_m = [\n",
    "    [0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-60f40d68dba2>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-60f40d68dba2>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    weight =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# congestion game potential\n",
    "\n",
    "\"\"\"\n",
    "input: \n",
    "# agents\n",
    "state game: congestion game\n",
    "env\n",
    "\n",
    "output:\n",
    "<phi, next state>\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "every state 对应一个 congestion game\n",
    "\"\"\"\n",
    "\n",
    "def phi_generator(n, state):\n",
    "    phi = dict()\n",
    "    s_next_n = n + 1   # agents unlabelled \n",
    "    weight = \n",
    "#     weight = env[state] \n",
    "    for i in range(s_next_n): # 0, 1 ,2\n",
    "        part1, part2 = 0, 0\n",
    "        m, v = 0, 0\n",
    "        for m in range(i):\n",
    "            part1 += weight[\"0\"](m+1) \n",
    "        for v in range(n-i):\n",
    "            part2 += weight[\"1\"](n+1)\n",
    "        phi[i] = part1 + part2\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 3, 2: 3}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_generator(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 agents; small\n",
    "# payoff matrix\n",
    "\n",
    "nS = 8\n",
    "nA = 3\n",
    "\n",
    "payoff = [\n",
    "    [-3, -3, -4], # [s,s]\n",
    "    [-2, -2, -3], # [a,a]\n",
    "    [-2, -2, -2], # [a,b]\n",
    "    [-2, -2, -3], # [b,b]\n",
    "    [-3, -10, -10], # [c,c]\n",
    "    [-10, -2, -10], # [c,d]\n",
    "    [-10, -10, -2],  # [d,d]\n",
    "    [0, 0, 0]     # [T,T]\n",
    "]\n",
    "transition =[\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6],\n",
    "    [7, 7, 7],\n",
    "    [7, 7, 7],\n",
    "    [7, 7, 7],\n",
    "    [7, 7, 7]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 agents; big\n",
    "# payoff matrix\n",
    "\n",
    "nS = 11\n",
    "nA = 3\n",
    "\n",
    "payoff = [\n",
    "    [-3, -3, -4], # [s,s] 1\n",
    "    [-2, -2, -3], # [a,a] 2\n",
    "    [-2, -2, -2], # [a,d] 3\n",
    "    [-2, -2, -3], # [d,d] 4\n",
    "    [-3, -3, -4], # [b,b] 5\n",
    "    [-2, -2, -2], # [b,e] 6\n",
    "    [-2, -2, -2],  # [e,e] 7\n",
    "    [-3, -10, -10], # [c,c] 8\n",
    "    [-10, -2, -10], # [c,f] 9\n",
    "    [-10, -10, -2], # [f,f] 10\n",
    "    [0, 0, 0]      #[T,T] 11\n",
    "]\n",
    "transition =[\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [7, 8, 9],\n",
    "    [7, 8, 9],\n",
    "    [10,10,10],\n",
    "    [10, 10, 10],\n",
    "    [10, 10, 10],\n",
    "    [10, 10, 10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(1, 1, -3, False)], 1: [(1, 2, -3, False)], 2: [(1, 3, -4, False)]},\n",
       " 1: {0: [(1, 4, -2, False)], 1: [(1, 5, -2, False)], 2: [(1, 6, -3, False)]},\n",
       " 2: {0: [(1, 4, -2, False)], 1: [(1, 5, -2, False)], 2: [(1, 6, -2, False)]},\n",
       " 3: {0: [(1, 4, -2, False)], 1: [(1, 5, -2, False)], 2: [(1, 6, -3, False)]},\n",
       " 4: {0: [(1, 7, -3, False)], 1: [(1, 8, -3, False)], 2: [(1, 9, -4, False)]},\n",
       " 5: {0: [(1, 7, -2, False)], 1: [(1, 8, -2, False)], 2: [(1, 9, -2, False)]},\n",
       " 6: {0: [(1, 7, -2, False)], 1: [(1, 8, -2, False)], 2: [(1, 9, -2, False)]},\n",
       " 7: {0: [(1, 10, -3, True)], 1: [(1, 10, -10, True)], 2: [(1, 10, -10, True)]},\n",
       " 8: {0: [(1, 10, -10, True)], 1: [(1, 10, -2, True)], 2: [(1, 10, -10, True)]},\n",
       " 9: {0: [(1, 10, -10, True)], 1: [(1, 10, -10, True)], 2: [(1, 10, -2, True)]},\n",
       " 10: {0: [(1, 10, 0, True)], 1: [(1, 10, 0, True)], 2: [(1, 10, 0, True)]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = dict()\n",
    "for s in range(nS):\n",
    "    P[s] = {a : [] for a in range(nA)}\n",
    "    \n",
    "for state in range(nS):\n",
    "    for a in range(nA):\n",
    "        tmp = []\n",
    "        prob = 1\n",
    "        snext = transition[state][a]\n",
    "        reward = payoff[state][a]\n",
    "        done = False\n",
    "        if snext == 10:\n",
    "            done = True\n",
    "        # prob, next_state, reward, done\n",
    "        tmp.extend([(prob, snext, reward, done)])\n",
    "        P[state][a] = tmp\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(theta=0.0001, discount_factor=1.0):\n",
    "    policy_list = []\n",
    "\n",
    "    def one_step_lookahead(state, V):\n",
    "        A = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            for prob, next_state, reward, done in P[state][a]:\n",
    "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
    "        return A\n",
    "\n",
    "    V = np.zeros(nS)\n",
    "    iter = 0\n",
    "    dl = []\n",
    "    vl = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        iter += 1\n",
    "        print(iter)\n",
    "        # Stopping condition\n",
    "        delta = 0\n",
    "        # Update each state...\n",
    "        for s in range(nS):\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10.\n",
    "            V[s] = best_action_value\n",
    "\n",
    "        vl.append(V.copy())\n",
    "        dl.append(delta)\n",
    "\n",
    "        # Check if we can stop\n",
    "        print(\"debug-> iter={}, delta={:.5f}, V={}\".format(iter, delta, V))\n",
    "#         if delta < theta:\n",
    "#             break\n",
    "        # Create a deterministic policy using the optimal value function\n",
    "        policy_iter = np.zeros([nS, nA])\n",
    "        for s in range(nS):\n",
    "            # One step lookahead to find the best action for this state\n",
    "            A = one_step_lookahead(s, V)\n",
    "            # pdb.set_trace()\n",
    "            policy_t = A\n",
    "            best_action = np.argmax(A)\n",
    "            # Always take the best action\n",
    "            # policy_iter[s, best_action] = 1.0\n",
    "            # soft policy\n",
    "            policy_iter[s, :] = policy_t # record action values\n",
    "        policy_list.append(policy_iter)\n",
    "        # print(\"policy\", policy_iter)\n",
    "\n",
    "    # Create a deterministic policy using the optimal value function\n",
    "    policy = np.zeros([nS, nA])\n",
    "    for s in range(nS):\n",
    "        # One step lookahead to find the best action for this state\n",
    "        A = one_step_lookahead(s, V)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        policy[s, best_action] = 1.0\n",
    "\n",
    "    return policy, V, dl, vl, policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "debug-> iter=1, delta=3.00000, V=[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "2\n",
      "debug-> iter=2, delta=2.00000, V=[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "3\n",
      "debug-> iter=3, delta=2.00000, V=[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "4\n",
      "debug-> iter=4, delta=2.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "5\n",
      "debug-> iter=5, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "6\n",
      "debug-> iter=6, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "7\n",
      "debug-> iter=7, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "8\n",
      "debug-> iter=8, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "9\n",
      "debug-> iter=9, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "10\n",
      "debug-> iter=10, delta=0.00000, V=[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n"
     ]
    }
   ],
   "source": [
    "policy, V, dl, vl, policy_list = value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAeDUlEQVR4nO3de3SV9Z3v8fc3N0gwmGASKAQnXBOocrERW1GUS8F2WuW0p3N6mRlt9ThOa1unLTN1PGPXtKunXYfWY69aj9rLjLYz7Vjb6dgCAlJRwQZEUCGEi1xCJeES5JJALt/zx97RFHcgG/bev335vNbai+xnP9n5sBfw4fn9nuf3mLsjIiIyUHmhA4iISGZRcYiISFxUHCIiEhcVh4iIxEXFISIicSkIHSDZKioqvKamJnQMEZGMsm7dugPuXhnrtawvjpqaGhoaGkLHEBHJKGa2q7/X0mKoyswWm9kWM9toZr80s7J+9rvOzBrNbJuZfTHVOUVEJE2KA1gGXOLuU4CtwJ2n72Bm+cD3gPcAk4GPmNnklKYUEZH0KA53X+ruXdGna4DqGLvNALa5+w53PwX8DLghVRlFRCQiLYrjNJ8Afhtj+yhgT5/ne6Pb3sLMbjWzBjNraG1tTUJEEZHclbLJcTN7EhgR46W73P1X0X3uArqAR2K9RYxtMRfacvcHgAcA6uvrtRiXiEgCpaw43H3emV43sxuB9wFzPfbKi3uB0X2eVwP7EpdQREQGIi2GqszsOuAfgOvd/UQ/u/0BmGBmY8ysCPgw8OtUZRQRkYi0KA7gu0ApsMzMNpjZ/QBmNtLMngCITp7fDiwBNgP/7u4vhwosIpKr0uICQHcf38/2fcB7+zx/AngiVbl6Pf5CM4uXNLKvrZ2RZcUsWlDLwukx5+VFRLJeWhRHOnv8hWbufGwT7Z3dADS3tXPnY5sAVB4ikpPSZagqbS1e0vhGafRq7+xm8ZLGQIlERMJScZzFvrb2uLaLiGQ7FcdZjCwrjmu7iEi2U3GcxaIFtRQX5v/JtuLCfBYtqA2USEQkLBXHWSycPoqvfeBSLiwuBGDo4AK+9oFLNTEuIjlLxTEAC6eP4r8+cxUAdSOGqjREJKepOAaouryEuhGlNOw6RNuJU6HjiIgEo+KIw5y6KnocVm3VirsikrtUHHGYO6kKgOWbWwInEREJR8URh2mjyykvKeSpxha6untCxxERCULFEYf8POPa2ipe7+hi3a7DoeOIiASh4ojTnLrIcNWKRg1XiUhuUnHEadbESvLzjBWa5xCRHKXiiNOFxYVcXlNOU8sxdh/s755TIiLZS8VxDubWDQdgxZb9gZOIiKSeiuMczOk9LXeLhqtEJPeoOM7B2Ioh1FxUwtodhzh2sit0HBGRlFJxnAMzY3ZdFae6e1jddCB0HBGRlFJxnKPeeY6VGq4SkRyj4jhHM8YMY0hRPisaW+jp8dBxRERSRsVxjooK8pg1sZLWoyd5ad+R0HFERFJGxXEeeq8i16KHIpJLVBzn4draKsxgheY5RCSHqDjOQ2XpIKZWl7Gp+Qj7X+8IHUdEJCVUHOepd7hKZ1eJSK5QcZynN+Y5VBwikiNUHOfp7SOHMnzoIJ7ZdoCOzu7QcUREkk7FcZ7MjDl1wzlxqpu1Ow+FjiMiknQqjgSY23tzp81aLVdEsp+KIwFmjq9gUEEey7e04K6ryEUku6k4EqC4KJ8rx13E3sPtNLUcCx1HRCSpVBwJoqvIRSRXqDgSZHbvPIfuCigiWU7FkSDV5SXUjShl3a7DtJ04FTqOiEjSpEVxmNliM9tiZhvN7JdmVtbPfq+a2SYz22BmDanOeTZz6qrocVi1tTV0FBGRpEmL4gCWAZe4+xRgK3DnGfad7e7T3L0+NdEGbu4kzXOISPZLi+Jw96Xu3nvz7jVAdcg852ra6HLKSwp5qrGFru6e0HFERJIiLYrjNJ8AftvPaw4sNbN1ZnZrf29gZreaWYOZNbS2pm7YKD/PmF1bxesdXazbdThlP1dEJJVSVhxm9qSZvRTjcUOffe4CuoBH+nmbme5+GfAe4FNmNivWTu7+gLvXu3t9ZWVlwn8vZ/Lm2VUarhKR7FSQqh/k7vPO9LqZ3Qi8D5jr/Vx+7e77or+2mNkvgRnA7xOd9XzMmlhJfp6xfEsLd753Uug4IiIJlxZDVWZ2HfAPwPXufqKffYaYWWnv18B84KXUpRyYC4sLubymnG0tx9h9MOZvRUQko6VFcQDfBUqBZdFTbe8HMLORZvZEdJ/hwGozexF4Hvgvd/9dmLhnNrduOKCLAUUkO6VsqOpM3H18P9v3Ae+Nfr0DmJrKXOdqzqQqvvrEZpZvaeGmmWNCxxERSah0OeLIKmMrhlBzUQlrdxzi2Mmus3+DiEgGUXEkQe/NnU5197C66UDoOCIiCaXiSJI5WvRQRLKUiiNJZowZxpCifFZsaaWnRzd3EpHsoeJIkqKCPGZNrOTAsZNsaj4SOo6ISMKoOJLojZs76SpyEckiKo4kura2CjNYqeIQkSyi4kiiytJBTK0uY1PzEfa/3hE6johIQqg4kmxudLhKRx0iki1UHEk2W/McIpJlVBxJ9vaRQxk+dBCrmw7Q0dkdOo6IyHlTcSRZ71Xk7Z3drNlxMHQcEZHzpuJIgbm6uZOIZBEVRwrMHF/BoII8VmxpoZ97VImIZAwVRwoUF+Vz5biL2Hu4naaWY6HjiIicFxVHisyZFLm50/LNGq4Skcym4kgRrZYrItlCxZEio8qKqRtRyrpdhzl8/FToOCIi50zFkUJz6qrocVi1tTV0FBGRc6biSKG5k3QVuYhkPhVHCk0bXU55SSGrGlvo6u4JHUdE5JyoOFIoP8+YXVvF6x1drNt1OHQcEZFzouJIsTmTdBW5iGQ2FUeKXT2hkvw80zyHiGQsFUeKXVhcyOU15WxrOcaug8dDxxERiZuKI4C5dZGryDVcJSKZSMURgOY5RCSTqTgCGFsxhJqLSliz4yDHTnaFjiMiEhcVRwC9N3fq7HZWNx0IHUdEJC4qjkDmTtKihyKSmVQcgVxeM4wLBhWwYksrPT26uZOIZI5zKg4zK0p0kFxTVJDH1RMqOHDsJJuaj4SOIyIyYOd6xPHPvV+Y2cwEZck5vffo0MWAIpJJzrU4lpjZrWb2MeA9iQyUS66trcJM8xwiklkK4v0GM3sIOAJMA9a4+z8mPFWOqCwdxNTqMjbsaeO1Ix2MuHBw6EgiImd11iMOM6vr+9zdbwbuAv4JaDGzH5xvCDP7ipltNLMNZrbUzEb2s9+NZtYUfdx4vj83HcyNDletbNRwlYhkhoEMVT1hZg+b2cW9G9y93d2fcfd73f1vEpBjsbtPcfdpwG+Au0/fwcyGAV8CrgBmAF8ys/IE/OygdBW5iGSagRRHHfACsMrM7jWzykSHcPfX+zwdAsQ6P3UBsMzdD7n7YWAZcF2is6Ta5LcNZcTQwaxuOkBHZ3foOCIiZ3XW4nD3U+7+HWASsBdYa2ZfNrPSRAYxs6+a2R7gY8Q44gBGAXv6PN8b3RbrvW41swYza2htTe/7e5sZs+uqaO/sZs2Og6HjiIic1YDPqnL3Dnf/BnAp0AGsN7MvDPT7zexJM3spxuOG6Pvf5e6jgUeA22O9RaxY/WR9wN3r3b2+sjLhB0gJ1zvPoeEqEckEAy4OM6sxs+uAW4CLgaPA/x7o97v7PHe/JMbjV6ft+ijwwRhvsRcY3ed5NbBvoD8/nc0cX8GggjyWb27BXVeRi0h6G8hZVRvN7BDwOHATUAasAG4ELkhECDOb0Ofp9cCWGLstAeabWXl0Unx+dFvGKy7K58pxF9Hc1s7W/cdCxxEROaOBXMfx34Adntz/Cn/dzGqBHmAXcBuAmdUDt7n7Le5+yMy+Avwh+j1fdvdDScyUUnMmDWdlYyvLt+yndkRCp49ERBJqIJPj25NcGrj7B6PDVlPc/f3u3hzd3uDut/TZ72F3Hx99/DCZmVKtd/mRFZs1zyEi6U2r46aJUWXF1I0oZf3uwxw+fip0HBGRfqk40sicuip6HFZtTe9TiEUktw1kcvxfor9+NvlxclvvzZ20Wq6IpLOBHHG8w8z+DPhE9IymYX0fyQ6YS6aNLqe8pJBVjS10dveEjiMiEtNAiuN+4HdElh5Zd9qjIXnRck9+njG7torXO7pYt+tw6DgiIjEN5Kyqb7v7JOBhdx/r7mP6PMamIGNO0aKHIpLu4lly5G/NbKqZ3R59TElmsFx19YRKCvKM5Zt1cycRSU/xLDnyGSLrSFVFH4+Y2aeTFSxXXVhcSH1NOdtbj7Pr4PHQcURE3iKe03FvAa5w97vd/W7gncD/TE6s3Da3bjig4SoRSU/xFIcBfW8Y0U3sFWvlPGmeQ0TSWTz3HP8hkXtx/DL6fCHwUOIjydiKIdRcVMKaHQc5drKLCwbFfWt4EZGkiWdy/B7g48Ah4DDwcXe/N1nBcpmZMaduOJ3dzuomXUUuIuklriVH3H199PTcb7n7C8kKJX2uIteihyKSZrRWVZq6vGYYFwwqYGVjCz09urmTiKQPFUeaKirI4+oJFRw4doqNzUdCxxEReYOKI43N0b3IRSQNxXMBYL2Z/dLM1kdvJ7vJzDYmM1yuu7a2CjNYsUVXkYtI+ojnPM9HgEXAJiK3eJUkqywdxNTqMjbsaeO1Ix2MuHBw6EgiInENVbW6+6/dfae77+p9JC2ZADA3Oly1slHDVSKSHuIpji+Z2YNm9hEz+0DvI2nJBHjzKnKdlisi6SKeoaqPE7knRyFvDlU58FiiQ8mbJr9tKCOGDuaZbQfo6OxmcGF+6EgikuPiKY6p7n5p0pJITGbG7Loqfvr8bp7bcZDZtVWhI4lIjotnqGqNmU1OWhLp1xvzHDotV0TSQDxHHFcBN5nZDuAkkZVx3d11Q6ckmzm+gsJ845E1u/nJc7sYVVbMogW1LJw+KnQ0EclB8RTHdUlLIWe05OXX6O5xelceaW5r587HNgGoPEQk5eIpjhv72f7lRASR/i1e0sjpy1W1d3azeEmjikNEUi6e4uh7H9PBwPuAzYmNI7Hsa2uPa7uISDINuDjc/Zt9n5vZN4BfJzyRvMXIsmKaY5TEyLLiAGlEJNedzyKHJcDYRAWR/i1aUEvxaddvDC7IY9GC2kCJRCSXDfiIw8w2EbngDyAfqETzGynRO4+xeEnjG0ce19ZVaX5DRIKIZ47jfX2+7gL2u3tXgvNIPxZOH8XC6aM4fPwUs/7PSp5pOkDbiVOUlRSFjiYiOSaeoaoZwKHowoYfB/7dzC5LTizpT/mQIm6+egxHT3Zx/6odoeOISA6Kpzj+yd2PmtlVwALgx8B9yYklZ3LzVWMoKynkR8/upOVoR+g4IpJj4imO7uivfw7c5+6/AjROEkDp4EJuu2YcHZ09fH/l9tBxRCTHxFMczWb2A+AvgCfMbFCc3y8JdOO7aqgsHcSja3fHPFVXRCRZ4vmH/y+AJcB17t4GDCNyR8DzZmZfid6OdoOZLTWzkf3s1x3dZ4OZ5fQ1JMVF+dw+ezynunv4zvKm0HFEJIcMuDjc/YS7P+buTdHnf3T3pQnKsdjdp7j7NOA3wN397Nfu7tOij+sT9LMz1odnjGZUWTE/X7eXnQeOn/0bREQSIC2Gmtz99T5Ph/Dm9SJyBoMK8vnM3PF09zjfenJr6DgikiPSojgAzOyrZrYH+Bj9H3EMNrMGM1tjZgvP8F63RvdraG1tTUredPHBy6oZUzGEX724j8bXjoaOIyI5IGXFYWZPmtlLMR43ALj7Xe4+GngEuL2ft7nY3euBjwL3mtm4WDu5+wPuXu/u9ZWVlUn5/aSLgvw87pg3AXe4Z1lj6DgikgNSVhzuPs/dL4nx+NVpuz4KfLCf99gX/XUH8BQwPamhM8T7p4ykdngpS17ez8a9baHjiEiWS4uhKjOb0Ofp9cCWGPuUR08BxswqgJnAK6lJmN7y8ozPzZ8IwDeXaq5DRJIrLYoD+Hp02GojMB/4LICZ1ZvZg9F9JgENZvYisBL4ururOKLmTx7O1OoLWbW1lT+8eih0HBHJYuae3Scw1dfXe0NDQ+gYKfH7ra389cPPM2PMMP7t1ndiZqEjiUiGMrN10Tnlt0iXIw5JgKsnVDCjZhjP7zzE000HQscRkSyl4sgiZsYXojd3+ubSRrL9aFJEwlBxZJkZY4Yxa2IlL+49wrJX9oeOIyJZSMWRhb4QPcPqnmVb6enRUYeIJJaKIwtNqS5j/uThbHntKP+5cV/oOCKSZVQcWerz82sxg3ufbKKruyd0HBHJIiqOLFU7opTrp45k54HjPLa+OXQcEckiKo4s9nfzJpKfZ3xreRMnu7rP/g0iIgOg4shiNRVD+NA7qmlua+dnz+8JHUdEsoSKI8t9eu4EivLz+O7KbbSf0lGHiJw/FUeWG1VWzEevuJjWoyf5yXOvho4jIllAxZEDPjl7HIML87hv1XaOdnSGjiMiGU7FkQOqSgdz05VjaDvRyUOrd4aOIyIZTsWRI/5m1lhKBxXw0NM7OXz8VOg4IpLBVBw5onxIETdfPYajJ7v4we93hI4jIhlMxZFDbr5qDOUlhfzo2Z20HO0IHUdEMpSKI4eUDi7ktmvG0dHZw/dXbg8dR0QylIojx/z1u2qoLB3Eo2t309zWHjqOiGQgFUeOKS7K5/bZ4znV3cN3ljeFjiMiGUjFkYM+PGM0o8qK+fm6vew8cDx0HBHJMCqOHDSoIJ/Pzp1Ad49z75NbQ8cRkQyj4shRH7hsFGMqhvDrF/fR+NrR0HFEJIOoOHJUQX4ed8ybgDvcs6wxdBwRySAqjhz2/ikjqRtRypKX97Nxb1voOCKSIVQcOSwvz/jcuycC8I2lmusQkYFRceS4d08eztTqC/n91lae33kodBwRyQAqjhxnZnx+fi0A31jSiLsHTiQi6U7FIVw9oYIZY4bx/KuHeLrpQOg4IpLmVByCmbFoQfSoY6mOOkTkzFQcAsDlNcO4ZmIlG/ceYekr+0PHEZE0puKQN3x+fuQMq3uWbqWnR0cdIhKbikPeMKW6jAVvH07j/qP858Z9oeOISJpSccif+Pz8Wszg3ieb6OruCR1HRNKQikP+xMThpdwwdSQ7DxznP9bvDR1HRNKQikPe4o55E8nPM769fBsnu7pDxxGRNJNWxWFmXzAzN7OKfl6/0cyaoo8bU50vV9RUDOFD76imua2dnz2/J3QcEUkzaVMcZjYaeDewu5/XhwFfAq4AZgBfMrPy1CXMLZ+eO4Gi/Dy+u3Ib7ad01CEib0qb4gD+L/D3QH/ngS4Alrn7IXc/DCwDrktVuFwzqqyYj15xMa1HT/Lj514NHUdE0khaFIeZXQ80u/uLZ9htFNB33GRvdFus97vVzBrMrKG1tTWBSXPLJ2ePY3BhHvev2s7Rjs7QcUQkTaSsOMzsSTN7KcbjBuAu4O6zvUWMbTGPTtz9AXevd/f6ysrK842es6pKB3PTlWNoO9HJQ6t3ho4jImkiZcXh7vPc/ZLTH8AOYAzwopm9ClQD681sxGlvsRcY3ed5NaCr1JLstmvGUjqogAef3snh46dCxxGRNBB8qMrdN7l7lbvXuHsNkYK4zN1fO23XJcB8MyuPTorPj26TJCorKeKWq8dy7GQX9/9+e+g4IpIGghfHmZhZvZk9CODuh4CvAH+IPr4c3SZJ9omraigvKeTHz75Ky9GO0HFEJDDL9iW06+vrvaGhIXSMjPeDVdv52m+3MKQonxOnuhlZVsyiBbUsnB7z/AQRyXBmts7d62O9VpDqMJKZykuKADgevaajua2dOx/bBKDyEMkxaT1UJenjW8ub3rKtvbObxUsaA6QRkZBUHDIg+9raY25v7me7iGQvFYcMyMiy4n5f+x8/eI7VTQd0y1mRHKHikAFZtKCW4sL8P9lWlJ/HmIuGsHbnIf7yobUs/P6zPPnKfhWISJbT5LgMSO8E+OIljexra3/jrKobpo1kzY5DfHdlE89sO8gtP2mgbkQpn5o9nvde+jby82Jd8C8imUyn40rCrN99mO+t2MbyLS0AjK0Ywt9eO46F00dRmK+DW5FMcqbTcVUcknCv7Hud7z21jSc2/RH3yEq7t107jg+9o5rBpw13iUh6UnGoOILY1nKM+57azuMbmunucapKB3HrrLF89IqLKSnSKKlIOlNxqDiC2nPoBPev2s7PG/ZyqruH8pJCbr5qDH/1rhouLC4MHU9EYlBxqDjSwmtHOvh/T+/g0bW7ae/spnRQATdeWcMnrhrDsCFFoeOJSB8qDhVHWjl47CQPP7OTnzy7i6MnuyguzOejV1zMrbPGMnzo4NDxRAQVh4ojTR1p7+Qnz77Kw8/s5PCJTory8/hQfTW3XTOO0cNKQscTyWkqDhVHWjt+sotH1+7mgad30Hr0JPl5xsJpo/jk7HGMq7wgdDyRnKTiUHFkhI7Obn6+bi/3P7Wd5rZ2zOC9l76NT107nskjh4aOJ5JTVBwqjozS2d3D4y808/2ntrPzwHEA5k2q4lOzx7Pr4Im3XL2e6mXdH3+hWRnSKIcyJCeDikPFkZG6e5wnNv2R763cxpbXjgKQZ9DT549scWE+X/vApSn7S/r4C83c+dgm2ju7czpDuuRQhuRlUHGoODJaT4+zfEsLn3xkHZ3db/3zmmdQWTooJVlaj578k+LK1QzpkkMZzpxhVFkxz3xxzjm9p+4AKBktL8949+ThMUsDIkcg3T2pyRLrL2cuZkiXHMpw5gz93UfnfKk4JGOMKiuOeeOo8/lfVbxmfn2FMqRRDmU4c4Yz3UfnfGjJUskYse4JUlyYz6IFtcqQ4gzpkkMZwmTQEYdkjP7uCZLKCWFlSK8cyhAmgybHRUTkLc40Oa6hKhERiYuKQ0RE4qLiEBGRuKg4REQkLioOERGJi4pDRETiouIQEZG4qDhERCQuWX8BoJm1ArsS9HYVwIEEvVcm0+cQoc/hTfosIrLpc/gzd6+M9ULWF0cimVlDf1dS5hJ9DhH6HN6kzyIiVz4HDVWJiEhcVBwiIhIXFUd8HggdIE3oc4jQ5/AmfRYROfE5aI5DRETioiMOERGJi4pDRETiouIYADO7zswazWybmX0xdJ4QzGy0ma00s81m9rKZfTZ0ptDMLN/MXjCz34TOEoqZlZnZL8xsS/TPxrtCZwrBzP4u+vfiJTP7qZkNDp0pmVQcZ2Fm+cD3gPcAk4GPmNnksKmC6AI+7+6TgHcCn8rRz6GvzwKbQ4cI7FvA79y9DphKDn4eZjYK+AxQ7+6XAPnAh8OmSi4Vx9nNALa5+w53PwX8DLghcKaUc/c/uvv66NdHifwDkdqbXKcRM6sG/hx4MHSWUMxsKDALeAjA3U+5e1vYVMEUAMVmVgCUAPsC50kqFcfZjQL29Hm+lxz+BxPAzGqA6cDasEmCuhf4e6AndJCAxgKtwA+jQ3YPmtmQ0KFSzd2bgW8Au4E/AkfcfWnYVMml4jg7i7EtZ89hNrMLgP8A7nD310PnCcHM3ge0uPu60FkCKwAuA+5z9+nAcSDn5gDNrJzIKMQYYCQwxMz+Mmyq5FJxnN1eYHSf59Vk+WFof8yskEhpPOLuj4XOE9BM4Hoze5XI0OUcM/vXsJGC2AvsdffeI89fECmSXDMP2Onure7eCTwGXBk4U1KpOM7uD8AEMxtjZkVEJr1+HThTypmZERnL3uzu94TOE5K73+nu1e5eQ+TPwwp3z+r/Ycbi7q8Be8ysNrppLvBKwEih7AbeaWYl0b8nc8nykwQKQgdId+7eZWa3A0uInC3xsLu/HDhWCDOBvwI2mdmG6LZ/dPcnAmaS8D4NPBL9T9UO4OOB86Scu681s18A64mcffgCWb70iJYcERGRuGioSkRE4qLiEBGRuKg4REQkLioOERGJi4pDRETiouIQSRIz+5qZXWtmC3tXVTazH5nZf49+fYeZlYRNKRI/FYdI8lxBZD2va4CnY7x+B5EF8QYsulqzSFAqDpEEM7PFZrYRuBx4DrgFuM/M7u6zz2eIrGu00sxWRrfNN7PnzGy9mf08ui4YZvaqmd1tZquBD6X8NyRyGhWHSIK5+yIiZfEjIuWx0d2nuPuX++zzbSJrns1299lmVgH8L2Ceu18GNACf6/O2He5+lbv/LFW/D5H+aMkRkeSYDmwA6hjY+k3vJHKjsGciyx1RRORopde/JTqgyLlScYgkkJlNI3KkUQ0cIDKHYdH1vc50W1UDlrn7R/p5/Xgic4qcDw1ViSSQu29w92nAViJHECuABe4+zd3bT9v9KFAa/XoNMNPMxgNEV1qdmKrcIvFQcYgkmJlVAofdvQeoc/f+hqoeAH5rZivdvRW4CfhpdGJ9DZFhLpG0o9VxRUQkLjriEBGRuKg4REQkLioOERGJi4pDRETiouIQEZG4qDhERCQuKg4REYnL/wcOx7LasozUsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### plot\n",
    "\n",
    "v1 = np.array(vl)\n",
    "x = np.arange(0, 10)\n",
    "mean_v = np.mean(v1,axis=1) # sum列；得到维度与行维度相同\n",
    "plt.plot(x, mean_v, linewidth=1.8)\n",
    "plt.scatter(x, mean_v)\n",
    "plt.xlabel('#Iter')\n",
    "plt.ylabel('sum of $V_k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal policy\n",
    "# ！！！ 有几个NE\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_estimate(R, policy, theta=0.0001, discount_factor=1.0):\n",
    "#     def one_step_lookahead(state, V):\n",
    "#         A = np.zeros(nA)\n",
    "#         for a in range(nA):\n",
    "#             for prob, next_state, reward, done in P[state][a]:\n",
    "#                 A[a] += prob * (discount_factor * R[s][a]) * policy[s][a]\n",
    "#         return A\n",
    "    def one_step_lookahead(state, V):\n",
    "        A = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            for prob, next_state, reward, done in P[state][a]:\n",
    "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
    "        return A\n",
    "    V = np.zeros(nS)\n",
    "    iter = 0\n",
    "    dl = []\n",
    "    vl = []\n",
    "    while True:\n",
    "        iter += 1\n",
    "        # Stopping condition\n",
    "        delta = 0\n",
    "        # Update each state...\n",
    "        for s in range(nS):\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10.\n",
    "            V[s] = np.max(A)\n",
    "        print(V)\n",
    "        vl.append(V.copy())\n",
    "        dl.append(delta)\n",
    "        # Check if we can stop\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return policy, V, dl, vl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ？？？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_return(policy_list):\n",
    "    # total return for agent 1\n",
    "    print(\"--> Start doing total return\")\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    iter = len(policy_list)\n",
    "\n",
    "    for idx in range(iter):\n",
    "        policy = policy_list[idx]\n",
    "        _, v, _, vl = value_estimate(env, R1, policy)\n",
    "        v1.append(v.copy())\n",
    "        _, v, _, vl = value_estimate(env, R2, policy)\n",
    "        v2.append(v.copy())\n",
    "\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    x = np.arange(0, iter)\n",
    "    mean_v = v1.sum(-1)\n",
    "    plt.plot(x, mean_v, linewidth=1.8)\n",
    "    plt.scatter(x, mean_v)\n",
    "    plt.xlabel('#Iter')\n",
    "    plt.ylabel('$V_k$ for agent 1')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.plot(x[1:-1], np.diff(mean_v)[1:], linewidth=1.8)\n",
    "    plt.scatter(x[1:-1], np.diff(mean_v)[1:])\n",
    "    plt.xlabel('#Iter')\n",
    "    plt.ylabel('$|V_k-V_{k-1}|$ for agent 1')\n",
    "    plt.show()\n",
    "    # agent 2\n",
    "    mean_v2 = v2.sum(-1)\n",
    "    plt.plot(x, mean_v2, linewidth=1.8)\n",
    "    plt.scatter(x, mean_v2)\n",
    "    plt.xlabel('#Iter')\n",
    "    plt.ylabel('$V_k$ for agent 2')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(x[1:-1], np.diff(mean_v2)[1:], linewidth=1.8)\n",
    "    plt.scatter(x[1:-1], np.diff(mean_v2)[1:])\n",
    "    plt.xlabel('#Iter')\n",
    "    plt.ylabel('$|V_k-V_{k-1}|$ for agent 1')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-3. -2. -2. -2. -3. -2. -2. -3. -2. -2.  0.]\n",
      "[-5. -4. -4. -4. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-7. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n",
      "[-9. -6. -6. -6. -5. -4. -4. -3. -2. -2.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# total return \n",
    "iter = len(policy_list)\n",
    "v1 = []\n",
    "for idx in range(iter):\n",
    "    policy = policy_list[idx]\n",
    "\n",
    "    _, v, _, vl = value_estimate(payoff, policy)\n",
    "    v1.append(v.copy())\n",
    "#     _, v, _, vl = value_estimate(env, R2, policy)\n",
    "#     v2.append(v.copy())\n",
    "\n",
    "v1 = np.array(v1)\n",
    "\n",
    "# v2 = np.array(v2)\n",
    "x = np.arange(0, iter)\n",
    "mean_v = v1.sum(-1) # sum列；得到维度与行维度相同\n",
    "plt.plot(x, mean_v, linewidth=1.8)\n",
    "plt.scatter(x, mean_v)\n",
    "plt.xlabel('#Iter')\n",
    "plt.ylabel('$V_k$ for agent 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 agents planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph representation\n",
    "# build up the graph with weights\n",
    "\n",
    "graph = {\n",
    "    \"0\": {\"1\": lambda x : x, \"0\": lambda x : 3},\n",
    "    \"1\": {\"1\": lambda x : 0.5*x, \"0\": lambda x : 1},\n",
    "    \"2\": {\"1\": lambda x : 0.5, \"0\": lambda x : 0.8*x},\n",
    "    \"3\": {\"0\": lambda x : 0, \"1\": lambda x: -10},\n",
    "    \"4\": {\"0\": lambda x : 1, \"1\": lambda x: -10}\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action space\n",
    "adjacency_m = [\n",
    "    [0, 1, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "adjacency_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_global = np.array(adjacency_m)\n",
    "action_global[0].nonzero()\n",
    "x = np.nonzero(action_global[0]) # 非0元素坐标\n",
    "action_global[0][x] # 取出非0元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state \n",
    "state = [\n",
    "    [4, 0, 0, 0, 0, 0], #0\n",
    "    [0, 1, 3, 0, 0, 0], #1\n",
    "    [0, 2, 2, 0, 0, 0], #2\n",
    "    [0, 3, 1, 0, 0, 0], #3\n",
    "    [0, 4, 0, 0, 0, 0], #4\n",
    "    [0, 0, 4, 0, 0, 0], #5\n",
    "    [0, 0, 0, 1, 3, 0], #6\n",
    "    [0, 0, 0, 2, 2, 0], #7\n",
    "    [0, 0, 0, 3, 1, 0], #8\n",
    "    [0, 0, 0, 4, 0, 0], #9\n",
    "    [0, 0, 0, 0, 4, 0], #10\n",
    "    [0, 0, 0, 0, 0, 4]  #11\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查list里面index\n",
    "state.index([4, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 0, 0, 0],\n",
       " 1: [0, 0, 0, 1],\n",
       " 2: [0, 0, 1, 0],\n",
       " 3: [0, 0, 1, 1],\n",
       " 4: [0, 1, 0, 0],\n",
       " 5: [0, 1, 0, 1],\n",
       " 6: [0, 1, 1, 0],\n",
       " 7: [0, 1, 1, 1],\n",
       " 8: [1, 0, 0, 0],\n",
       " 9: [1, 0, 0, 1],\n",
       " 10: [1, 0, 1, 0],\n",
       " 11: [1, 0, 1, 1],\n",
       " 12: [1, 1, 0, 0],\n",
       " 13: [1, 1, 0, 1],\n",
       " 14: [1, 1, 1, 0],\n",
       " 15: [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = dict()\n",
    "for a in range(16):\n",
    "    action[a] = bit_to_list(a, 4) # 4 means # agents\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5., 1., 1., 2., 1., 2., 2., 3., 1., 2., 2., 3., 2., 3., 3., 4.]),\n",
       " array([10.,  6.,  6.,  7.,  6.,  7.,  7.,  8.,  6.,  7.,  7.,  8.,  7.,\n",
       "         8.,  8.,  9.]),\n",
       " array([10.,  6.,  6.,  7.,  6.,  7.,  7.,  8.,  6.,  7.,  7.,  8.,  7.,\n",
       "         8.,  8.,  9.]),\n",
       " array([10.,  6.,  6.,  7.,  6.,  7.,  7.,  8.,  6.,  7.,  7.,  8.,  7.,\n",
       "         8.,  8.,  9.]),\n",
       " array([10.,  6.,  6.,  7.,  6.,  7.,  7.,  8.,  6.,  7.,  7.,  8.,  7.,\n",
       "         8.,  8.,  9.]),\n",
       " array([10.,  6.,  6.,  7.,  6.,  7.,  7.,  8.,  6.,  7.,  7.,  8.,  7.,\n",
       "         8.,  8.,  9.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.]),\n",
       " array([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.,\n",
       "        11., 11., 11.])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator(state, action):\n",
    "    transition = []\n",
    "    nS = len(state)\n",
    "    nA = len(action)\n",
    "    state_n = np.zeros(nA)\n",
    "    transition = []\n",
    "    # start: all at s \n",
    "    \n",
    "    for a in range(nA):\n",
    "        # 0  --> down\n",
    "        # 1  --> up \n",
    "        s = sum(action[a])\n",
    "        state_n[a] = state.index([0, s, (4-s), 0, 0, 0])\n",
    "        \n",
    "    transition.append(state_n)\n",
    "    state_n = np.zeros(nA)\n",
    "    for _ in range(5):\n",
    "        for a in range(nA):\n",
    "            s = sum(action[a])\n",
    "            state_n[a] = state.index([0, 0, 0, s, (4-s), 0])\n",
    "        transition.append(state_n)\n",
    "    state_n = np.zeros(nA) + 11\n",
    "    for _ in range(6):\n",
    "        transition.append(state_n)\n",
    "    return transition\n",
    "\n",
    "transition = generator(state, action)\n",
    "len(transition) # 12\n",
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congestion game potential\n",
    "\n",
    "\"\"\"\n",
    "input: \n",
    "# agents\n",
    "state game: congestion game\n",
    "env\n",
    "\n",
    "output:\n",
    "<phi, next state>\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "every state 对应一个 congestion game\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def phi_generator(n, state, action, transition):\n",
    "    # 0  --> down\n",
    "    # 1  --> up \n",
    "    phi = []\n",
    "    \n",
    "    # at step 0\n",
    "    reward = np.zeros(len(action))\n",
    "    for a in range(len(action)):\n",
    "        act = action[a]\n",
    "        s = sum(act) # count how many 1\n",
    "        part1, part2 = 0, 0\n",
    "        m, v = 0, 0\n",
    "        for m in range(s):\n",
    "            part1 += graph[\"0\"][\"1\"](m+1)\n",
    "        for v in range(n-s):\n",
    "            part2 += graph[\"0\"][\"0\"](v+1)\n",
    "        reward[a] = part1 + part2\n",
    "    phi.append(reward)\n",
    "    \n",
    "    # at node A,D \n",
    "    for i in range(1,6):\n",
    "        mark = state[i][1]\n",
    "        reward = np.zeros(len(action))\n",
    "        for a in range(len(action)):\n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            \n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            s_ = sum(action[a][0:mark])\n",
    "            for m in range(s_):\n",
    "                part1 += graph[\"1\"][\"1\"](m+1)\n",
    "            for v in range(mark-s_):\n",
    "                part2 += graph[\"1\"][\"0\"](v+1)\n",
    "                    \n",
    "            part3, part4 = 0, 0\n",
    "            j, w = 0, 0\n",
    "            s__ = s - s_\n",
    "            for j in range(s__):\n",
    "                part3 += graph[\"2\"][\"1\"](j+1)\n",
    "            for w in range(4-mark-s__):\n",
    "                part4 += graph[\"2\"][\"0\"](w+1)\n",
    "            reward[a] = part1 + part2 + part3 + part4\n",
    "        phi.append(reward)\n",
    "    \n",
    "    # at node B, E\n",
    "    \n",
    "    for i in range(6,11):\n",
    "        mark_ = state[i][3]\n",
    "        reward = np.zeros(len(action))\n",
    "        a = 0\n",
    "        for a in range(len(action)):\n",
    "            \n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            zero_c = act[0:mark_].count(0)\n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            if (zero_c == mark_) and (s == state[i][4]):\n",
    "                for m in range(mark_):\n",
    "                    part1 += graph[\"3\"][\"0\"](m)\n",
    "                for v in range(state[i][4]):\n",
    "                    part2 += graph[\"4\"][\"0\"](v)\n",
    "                reward[a] = part1 + part2\n",
    "            else:\n",
    "                reward[a] = 20\n",
    "        phi.append(reward)\n",
    "        \n",
    "    # at terminal\n",
    "    reward = np.zeros(len(action))\n",
    "    phi.append(reward)\n",
    "        \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([12., 10., 10.,  9., 10.,  9.,  9.,  9., 10.,  9.,  9.,  9.,  9.,\n",
       "         9.,  9., 10.]),\n",
       " array([5.8, 3.9, 3.9, 2.8, 3.9, 2.8, 2.8, 2.5, 5.3, 3.4, 3.4, 2.3, 3.4,\n",
       "        2.3, 2.3, 2. ]),\n",
       " array([4.4, 3.3, 3.3, 3. , 3.9, 2.8, 2.8, 2.5, 3.9, 2.8, 2.8, 2.5, 3.9,\n",
       "        2.8, 2.8, 2.5]),\n",
       " array([3.8, 3.5, 3.3, 3. , 3.3, 3. , 3.3, 3. , 3.3, 3. , 3.3, 3. , 3.3,\n",
       "        3. , 3.8, 3.5]),\n",
       " array([4. , 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 4. , 3.5, 3.5, 3.5, 4. , 3.5,\n",
       "        4. , 4. , 5. ]),\n",
       " array([8. , 5.3, 5.3, 3.4, 5.3, 3.4, 3.4, 2.3, 5.3, 3.4, 3.4, 2.3, 3.4,\n",
       "        2.3, 2.3, 2. ]),\n",
       " array([20., 20., 20., 20., 20., 20., 20.,  3., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20.]),\n",
       " array([20., 20., 20.,  2., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20.]),\n",
       " array([20.,  1., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n",
       "        20., 20., 20.]),\n",
       " array([20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20., 20.,\n",
       "        20., 20.,  4.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payoff = phi_generator(4, state, action, transition)\n",
    "payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 agents; small\n",
    "# payoff matrix\n",
    "\n",
    "nS = 12\n",
    "nA = 16\n",
    "\n",
    "payoff = phi_generator(4, state, action, transition)\n",
    "payoff = -np.array(payoff)\n",
    "transition = generator(state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {0: [(1, 5, -12.0, False)],\n",
       "  1: [(1, 1, -10.0, False)],\n",
       "  2: [(1, 1, -10.0, False)],\n",
       "  3: [(1, 2, -9.0, False)],\n",
       "  4: [(1, 1, -10.0, False)],\n",
       "  5: [(1, 2, -9.0, False)],\n",
       "  6: [(1, 2, -9.0, False)],\n",
       "  7: [(1, 3, -9.0, False)],\n",
       "  8: [(1, 1, -10.0, False)],\n",
       "  9: [(1, 2, -9.0, False)],\n",
       "  10: [(1, 2, -9.0, False)],\n",
       "  11: [(1, 3, -9.0, False)],\n",
       "  12: [(1, 2, -9.0, False)],\n",
       "  13: [(1, 3, -9.0, False)],\n",
       "  14: [(1, 3, -9.0, False)],\n",
       "  15: [(1, 4, -10.0, False)]},\n",
       " 1: {0: [(1, 10, -5.800000000000001, False)],\n",
       "  1: [(1, 6, -3.9000000000000004, False)],\n",
       "  2: [(1, 6, -3.9000000000000004, False)],\n",
       "  3: [(1, 7, -2.8, False)],\n",
       "  4: [(1, 6, -3.9000000000000004, False)],\n",
       "  5: [(1, 7, -2.8, False)],\n",
       "  6: [(1, 7, -2.8, False)],\n",
       "  7: [(1, 8, -2.5, False)],\n",
       "  8: [(1, 6, -5.300000000000001, False)],\n",
       "  9: [(1, 7, -3.4000000000000004, False)],\n",
       "  10: [(1, 7, -3.4000000000000004, False)],\n",
       "  11: [(1, 8, -2.3, False)],\n",
       "  12: [(1, 7, -3.4000000000000004, False)],\n",
       "  13: [(1, 8, -2.3, False)],\n",
       "  14: [(1, 8, -2.3, False)],\n",
       "  15: [(1, 9, -2.0, False)]},\n",
       " 2: {0: [(1, 10, -4.4, False)],\n",
       "  1: [(1, 6, -3.3, False)],\n",
       "  2: [(1, 6, -3.3, False)],\n",
       "  3: [(1, 7, -3.0, False)],\n",
       "  4: [(1, 6, -3.9000000000000004, False)],\n",
       "  5: [(1, 7, -2.8, False)],\n",
       "  6: [(1, 7, -2.8, False)],\n",
       "  7: [(1, 8, -2.5, False)],\n",
       "  8: [(1, 6, -3.9000000000000004, False)],\n",
       "  9: [(1, 7, -2.8, False)],\n",
       "  10: [(1, 7, -2.8, False)],\n",
       "  11: [(1, 8, -2.5, False)],\n",
       "  12: [(1, 7, -3.9000000000000004, False)],\n",
       "  13: [(1, 8, -2.8, False)],\n",
       "  14: [(1, 8, -2.8, False)],\n",
       "  15: [(1, 9, -2.5, False)]},\n",
       " 3: {0: [(1, 10, -3.8, False)],\n",
       "  1: [(1, 6, -3.5, False)],\n",
       "  2: [(1, 6, -3.3, False)],\n",
       "  3: [(1, 7, -3.0, False)],\n",
       "  4: [(1, 6, -3.3, False)],\n",
       "  5: [(1, 7, -3.0, False)],\n",
       "  6: [(1, 7, -3.3, False)],\n",
       "  7: [(1, 8, -3.0, False)],\n",
       "  8: [(1, 6, -3.3, False)],\n",
       "  9: [(1, 7, -3.0, False)],\n",
       "  10: [(1, 7, -3.3, False)],\n",
       "  11: [(1, 8, -3.0, False)],\n",
       "  12: [(1, 7, -3.3, False)],\n",
       "  13: [(1, 8, -3.0, False)],\n",
       "  14: [(1, 8, -3.8, False)],\n",
       "  15: [(1, 9, -3.5, False)]},\n",
       " 4: {0: [(1, 10, -4.0, False)],\n",
       "  1: [(1, 6, -3.5, False)],\n",
       "  2: [(1, 6, -3.5, False)],\n",
       "  3: [(1, 7, -3.5, False)],\n",
       "  4: [(1, 6, -3.5, False)],\n",
       "  5: [(1, 7, -3.5, False)],\n",
       "  6: [(1, 7, -3.5, False)],\n",
       "  7: [(1, 8, -4.0, False)],\n",
       "  8: [(1, 6, -3.5, False)],\n",
       "  9: [(1, 7, -3.5, False)],\n",
       "  10: [(1, 7, -3.5, False)],\n",
       "  11: [(1, 8, -4.0, False)],\n",
       "  12: [(1, 7, -3.5, False)],\n",
       "  13: [(1, 8, -4.0, False)],\n",
       "  14: [(1, 8, -4.0, False)],\n",
       "  15: [(1, 9, -5.0, False)]},\n",
       " 5: {0: [(1, 10, -8.0, False)],\n",
       "  1: [(1, 6, -5.300000000000001, False)],\n",
       "  2: [(1, 6, -5.300000000000001, False)],\n",
       "  3: [(1, 7, -3.4000000000000004, False)],\n",
       "  4: [(1, 6, -5.300000000000001, False)],\n",
       "  5: [(1, 7, -3.4000000000000004, False)],\n",
       "  6: [(1, 7, -3.4000000000000004, False)],\n",
       "  7: [(1, 8, -2.3, False)],\n",
       "  8: [(1, 6, -5.300000000000001, False)],\n",
       "  9: [(1, 7, -3.4000000000000004, False)],\n",
       "  10: [(1, 7, -3.4000000000000004, False)],\n",
       "  11: [(1, 8, -2.3, False)],\n",
       "  12: [(1, 7, -3.4000000000000004, False)],\n",
       "  13: [(1, 8, -2.3, False)],\n",
       "  14: [(1, 8, -2.3, False)],\n",
       "  15: [(1, 9, -2.0, False)]},\n",
       " 6: {0: [(1, 11, -20.0, True)],\n",
       "  1: [(1, 11, -20.0, True)],\n",
       "  2: [(1, 11, -20.0, True)],\n",
       "  3: [(1, 11, -20.0, True)],\n",
       "  4: [(1, 11, -20.0, True)],\n",
       "  5: [(1, 11, -20.0, True)],\n",
       "  6: [(1, 11, -20.0, True)],\n",
       "  7: [(1, 11, -3.0, True)],\n",
       "  8: [(1, 11, -20.0, True)],\n",
       "  9: [(1, 11, -20.0, True)],\n",
       "  10: [(1, 11, -20.0, True)],\n",
       "  11: [(1, 11, -20.0, True)],\n",
       "  12: [(1, 11, -20.0, True)],\n",
       "  13: [(1, 11, -20.0, True)],\n",
       "  14: [(1, 11, -20.0, True)],\n",
       "  15: [(1, 11, -20.0, True)]},\n",
       " 7: {0: [(1, 11, -20.0, True)],\n",
       "  1: [(1, 11, -20.0, True)],\n",
       "  2: [(1, 11, -20.0, True)],\n",
       "  3: [(1, 11, -2.0, True)],\n",
       "  4: [(1, 11, -20.0, True)],\n",
       "  5: [(1, 11, -20.0, True)],\n",
       "  6: [(1, 11, -20.0, True)],\n",
       "  7: [(1, 11, -20.0, True)],\n",
       "  8: [(1, 11, -20.0, True)],\n",
       "  9: [(1, 11, -20.0, True)],\n",
       "  10: [(1, 11, -20.0, True)],\n",
       "  11: [(1, 11, -20.0, True)],\n",
       "  12: [(1, 11, -20.0, True)],\n",
       "  13: [(1, 11, -20.0, True)],\n",
       "  14: [(1, 11, -20.0, True)],\n",
       "  15: [(1, 11, -20.0, True)]},\n",
       " 8: {0: [(1, 11, -20.0, True)],\n",
       "  1: [(1, 11, -1.0, True)],\n",
       "  2: [(1, 11, -20.0, True)],\n",
       "  3: [(1, 11, -20.0, True)],\n",
       "  4: [(1, 11, -20.0, True)],\n",
       "  5: [(1, 11, -20.0, True)],\n",
       "  6: [(1, 11, -20.0, True)],\n",
       "  7: [(1, 11, -20.0, True)],\n",
       "  8: [(1, 11, -20.0, True)],\n",
       "  9: [(1, 11, -20.0, True)],\n",
       "  10: [(1, 11, -20.0, True)],\n",
       "  11: [(1, 11, -20.0, True)],\n",
       "  12: [(1, 11, -20.0, True)],\n",
       "  13: [(1, 11, -20.0, True)],\n",
       "  14: [(1, 11, -20.0, True)],\n",
       "  15: [(1, 11, -20.0, True)]},\n",
       " 9: {0: [(1, 11, -0.0, True)],\n",
       "  1: [(1, 11, -20.0, True)],\n",
       "  2: [(1, 11, -20.0, True)],\n",
       "  3: [(1, 11, -20.0, True)],\n",
       "  4: [(1, 11, -20.0, True)],\n",
       "  5: [(1, 11, -20.0, True)],\n",
       "  6: [(1, 11, -20.0, True)],\n",
       "  7: [(1, 11, -20.0, True)],\n",
       "  8: [(1, 11, -20.0, True)],\n",
       "  9: [(1, 11, -20.0, True)],\n",
       "  10: [(1, 11, -20.0, True)],\n",
       "  11: [(1, 11, -20.0, True)],\n",
       "  12: [(1, 11, -20.0, True)],\n",
       "  13: [(1, 11, -20.0, True)],\n",
       "  14: [(1, 11, -20.0, True)],\n",
       "  15: [(1, 11, -20.0, True)]},\n",
       " 10: {0: [(1, 11, -20.0, True)],\n",
       "  1: [(1, 11, -20.0, True)],\n",
       "  2: [(1, 11, -20.0, True)],\n",
       "  3: [(1, 11, -20.0, True)],\n",
       "  4: [(1, 11, -20.0, True)],\n",
       "  5: [(1, 11, -20.0, True)],\n",
       "  6: [(1, 11, -20.0, True)],\n",
       "  7: [(1, 11, -20.0, True)],\n",
       "  8: [(1, 11, -20.0, True)],\n",
       "  9: [(1, 11, -20.0, True)],\n",
       "  10: [(1, 11, -20.0, True)],\n",
       "  11: [(1, 11, -20.0, True)],\n",
       "  12: [(1, 11, -20.0, True)],\n",
       "  13: [(1, 11, -20.0, True)],\n",
       "  14: [(1, 11, -20.0, True)],\n",
       "  15: [(1, 11, -4.0, True)]},\n",
       " 11: {0: [(1, 11, -0.0, True)],\n",
       "  1: [(1, 11, -0.0, True)],\n",
       "  2: [(1, 11, -0.0, True)],\n",
       "  3: [(1, 11, -0.0, True)],\n",
       "  4: [(1, 11, -0.0, True)],\n",
       "  5: [(1, 11, -0.0, True)],\n",
       "  6: [(1, 11, -0.0, True)],\n",
       "  7: [(1, 11, -0.0, True)],\n",
       "  8: [(1, 11, -0.0, True)],\n",
       "  9: [(1, 11, -0.0, True)],\n",
       "  10: [(1, 11, -0.0, True)],\n",
       "  11: [(1, 11, -0.0, True)],\n",
       "  12: [(1, 11, -0.0, True)],\n",
       "  13: [(1, 11, -0.0, True)],\n",
       "  14: [(1, 11, -0.0, True)],\n",
       "  15: [(1, 11, -0.0, True)]}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = dict()\n",
    "nS = len(state)\n",
    "nA = len(action)\n",
    "print(nS, nA)\n",
    "for s in range(nS):\n",
    "    P[s] = {a : [] for a in range(nA)}\n",
    "    \n",
    "for state in range(nS):\n",
    "    for a in range(nA):\n",
    "        tmp = []\n",
    "        prob = 1\n",
    "        snext = transition[state][a]\n",
    "        reward = payoff[state][a]\n",
    "        done = False\n",
    "        if snext == 11:\n",
    "            done = True\n",
    "        # prob, next_state, reward, done\n",
    "        tmp.extend([(prob, int(snext), reward, done)])\n",
    "        P[state][a] = tmp\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "debug-> iter=1, delta=9.00000, V=[-9.  -2.  -2.5 -3.  -3.5 -2.  -3.  -2.  -1.   0.  -4.   0. ]\n",
      "2\n",
      "debug-> iter=2, delta=2.50000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "3\n",
      "debug-> iter=3, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "4\n",
      "debug-> iter=4, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "5\n",
      "debug-> iter=5, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "6\n",
      "debug-> iter=6, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "7\n",
      "debug-> iter=7, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "8\n",
      "debug-> iter=8, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "9\n",
      "debug-> iter=9, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n",
      "10\n",
      "debug-> iter=10, delta=0.00000, V=[-11.5  -2.   -2.5  -3.5  -5.   -2.   -3.   -2.   -1.    0.   -4.    0. ]\n"
     ]
    }
   ],
   "source": [
    "policy, V, dl, vl, policy_list = value_iteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    \"0\": {\"1\": lambda x : x,            \"0\": lambda x : 5},\n",
    "    \"1\": {\"1\": lambda x : 0.5*x,        \"0\": lambda x : 3},\n",
    "    \"2\": {\"1\": lambda x : 0.5*x,        \"0\": lambda x : (0.5*x+1)},\n",
    "    \"3\": {\"1\": lambda x : 0.5*x,        \"0\": lambda x: 3},\n",
    "    \"4\": {\"1\": lambda x : 10,           \"0\": lambda x: 2},\n",
    "    \"5\": {\"1\": lambda x : x,            \"0\": lambda x: 10},\n",
    "    \"6\": {\"1\": lambda x : 0.5*x,        \"0\": lambda x: (0.5*x+1)},\n",
    "    \"7\": {\"0\": lambda x : 5,            \"1\": lambda x: 10},\n",
    "    \"8\": {\"0\": lambda x : x,            \"1\": lambda x: 10},\n",
    "    \"9\": {}\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state \n",
    "state = [\n",
    "    [4, 0, 0, 0, 0, 0], #0\n",
    "    [0, 1, 3, 0, 0, 0], #1\n",
    "    [0, 2, 2, 0, 0, 0], #2\n",
    "    [0, 3, 1, 0, 0, 0], #3\n",
    "    [0, 4, 0, 0, 0, 0], #4\n",
    "    [0, 0, 4, 0, 0, 0], #5\n",
    "    [0, 0, 0, 1, 3, 0], #6\n",
    "    [0, 0, 0, 2, 2, 0], #7\n",
    "    [0, 0, 0, 3, 1, 0], #8\n",
    "    [0, 0, 0, 4, 0, 0], #9\n",
    "    [0, 0, 0, 0, 4, 0], #10\n",
    "    [0, 0, 0, 0, 0, 4]  #11\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 0], 1: [0, 1], 2: [1, 0], 3: [1, 1]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def action_generator(n):\n",
    "    action = dict()\n",
    "    nA = 2**n\n",
    "    for a in range(nA):\n",
    "        action[a] = bit_to_list(a, n) # 4 means # agents\n",
    "    return action\n",
    "action = action_generator(2)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_generator(n):\n",
    "    \n",
    "    node_n = len(graph)\n",
    "    nS = int(2 + ((node_n - 2)/2) * (n + 1))\n",
    "    state = np.zeros((nS, len(graph)))\n",
    "    mark = node_n - 2\n",
    "    \n",
    "    # 0\n",
    "    state[0][0] = 5\n",
    "    \n",
    "    i = 0 \n",
    "    m = 1\n",
    "    for s in range(1, (nS-1)):\n",
    "        state[s][m] =  i \n",
    "        state[s][m+1] = 5 - i\n",
    "        i += 1\n",
    "        if i >= (n+1):\n",
    "            i = 0 \n",
    "            m += 2\n",
    "    state[-1][-1] = 5\n",
    "    state = state.astype(int)\n",
    "    return state.tolist()\n",
    "\n",
    "state = state_generator(5)\n",
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_generator(state, action, n):\n",
    "    \n",
    "    # 0  --> down\n",
    "    # 1  --> up \n",
    "    \n",
    "    transition = []\n",
    "    nS = len(state)\n",
    "    nA = len(action)\n",
    "    state_n = np.zeros(nA)\n",
    "\n",
    "    # start: all at s \n",
    "    \n",
    "    for a in range(nA):\n",
    "        s = sum(action[a])\n",
    "        state_n[a] = state.index([0, s, (n-s), 0, 0, 0, 0, 0, 0, 0])\n",
    "    transition.append(state_n)\n",
    "    \n",
    "    # node 1; 2\n",
    "    for _ in range(n+1):\n",
    "        state_n = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            s = sum(action[a])\n",
    "            state_n[a] = state.index([0, 0, 0, s, (n-s), 0, 0, 0, 0, 0])\n",
    "        transition.append(state_n)\n",
    "    \n",
    "    # node 3; 4\n",
    "    for _ in range(n+1):\n",
    "        state_n = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            s = sum(action[a])\n",
    "            state_n[a] = state.index([0, 0, 0, 0, 0, s, (n-s), 0, 0, 0])\n",
    "        transition.append(state_n)\n",
    "    \n",
    "    # node 5; 6\n",
    "    for _ in range(n+1):\n",
    "        state_n = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            s = sum(action[a])\n",
    "            state_n[a] = state.index([0, 0, 0, 0, 0, 0, 0, s, (n-s), 0])\n",
    "        transition.append(state_n)\n",
    "    \n",
    "    # node 7; 8\n",
    "    state_n = np.zeros(nA) + 25\n",
    "    for _ in range(n+2):\n",
    "        transition.append(state_n)\n",
    "    \n",
    "    return transition\n",
    "transition = transition_generator(state, action, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 2., 2., 3.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([7., 8., 8., 9.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([13., 14., 14., 15.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([19., 20., 20., 21.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.]),\n",
       " array([25., 25., 25., 25.])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_generator(n, state, action, transition):\n",
    "    # 0  --> down\n",
    "    # 1  --> up \n",
    "    \n",
    "    phi = []\n",
    "    \n",
    "    # at step 0\n",
    "    reward = np.zeros(len(action))\n",
    "    for a in range(len(action)):\n",
    "        act = action[a]\n",
    "        s = sum(act) # count how many 1\n",
    "        part1, part2 = 0, 0\n",
    "        m, v = 0, 0\n",
    "        for m in range(s):\n",
    "            part1 += graph[\"0\"][\"1\"](m+1)\n",
    "        for v in range(n-s):\n",
    "            part2 += graph[\"0\"][\"0\"](v+1)\n",
    "        reward[a] = part1 + part2\n",
    "    phi.append(reward)\n",
    "    \n",
    "    \n",
    "    # at node 1,2\n",
    "    for i in range(1,n+2):\n",
    "        mark = state[i][1]\n",
    "        reward = np.zeros(len(action))\n",
    "        for a in range(len(action)):\n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            \n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            s_ = sum(action[a][0:mark])\n",
    "            for m in range(s_):\n",
    "                part1 += graph[\"1\"][\"1\"](m+1)\n",
    "            for v in range(mark-s_):\n",
    "                part2 += graph[\"1\"][\"0\"](v+1)\n",
    "                    \n",
    "            part3, part4 = 0, 0\n",
    "            j, w = 0, 0\n",
    "            s__ = s - s_\n",
    "            for j in range(s__):\n",
    "                part3 += graph[\"2\"][\"1\"](j+1)\n",
    "            for w in range(n-mark-s__):\n",
    "                part4 += graph[\"2\"][\"0\"](w+1)\n",
    "            reward[a] = part1 + part2 + part3 + part4\n",
    "        phi.append(reward)\n",
    "    \n",
    "    # at node 3, 4\n",
    "    for i in range(1,n+2):\n",
    "        mark = state[i][1]\n",
    "        reward = np.zeros(len(action))\n",
    "        for a in range(len(action)):\n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            \n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            s_ = sum(action[a][0:mark])\n",
    "            for m in range(s_):\n",
    "                part1 += graph[\"3\"][\"1\"](m+1)\n",
    "            for v in range(mark-s_):\n",
    "                part2 += graph[\"3\"][\"0\"](v+1)\n",
    "                    \n",
    "            part3, part4 = 0, 0\n",
    "            j, w = 0, 0\n",
    "            s__ = s - s_\n",
    "            for j in range(s__):\n",
    "                part3 += graph[\"4\"][\"1\"](j+1)\n",
    "            for w in range(n-mark-s__):\n",
    "                part4 += graph[\"4\"][\"0\"](w+1)\n",
    "            reward[a] = part1 + part2 + part3 + part4\n",
    "        phi.append(reward)\n",
    "    \n",
    "    # at node 5, 6\n",
    "    for i in range(1,n+2):\n",
    "        mark = state[i][1]\n",
    "        reward = np.zeros(len(action))\n",
    "        for a in range(len(action)):\n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            \n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            s_ = sum(action[a][0:mark])\n",
    "            for m in range(s_):\n",
    "                part1 += graph[\"5\"][\"1\"](m+1)\n",
    "            for v in range(mark-s_):\n",
    "                part2 += graph[\"5\"][\"0\"](v+1)\n",
    "                    \n",
    "            part3, part4 = 0, 0\n",
    "            j, w = 0, 0\n",
    "            s__ = s - s_\n",
    "            for j in range(s__):\n",
    "                part3 += graph[\"6\"][\"1\"](j+1)\n",
    "            for w in range(n-mark-s__):\n",
    "                part4 += graph[\"6\"][\"0\"](w+1)\n",
    "            reward[a] = part1 + part2 + part3 + part4\n",
    "        phi.append(reward)\n",
    "\n",
    "    # at node 7,8\n",
    "    for i in range(19,25):\n",
    "        mark_ = state[i][3]\n",
    "        reward = np.zeros(len(action))\n",
    "        a = 0\n",
    "        for a in range(len(action)):\n",
    "            \n",
    "            act = action[a]\n",
    "            s = sum(act)\n",
    "            zero_c = act[0:mark_].count(0)\n",
    "            part1, part2 = 0, 0\n",
    "            m, v = 0, 0\n",
    "            if (zero_c == mark_) and (s == state[i][4]):\n",
    "                for m in range(mark_):\n",
    "                    part1 += graph[\"7\"][\"0\"](m)\n",
    "                for v in range(state[i][4]):\n",
    "                    part2 += graph[\"8\"][\"0\"](v)\n",
    "                reward[a] = part1 + part2\n",
    "            else:\n",
    "                reward[a] = 20\n",
    "        phi.append(reward)\n",
    "        \n",
    "    # at terminal\n",
    "    reward = np.zeros(len(action))\n",
    "    phi.append(reward)\n",
    "        \n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([25., 21., 21., 18.]),\n",
       " array([12.5,  9.5,  9.5,  7.5]),\n",
       " array([12. ,  9.5,  9.5,  7. ]),\n",
       " array([12. ,  9.5,  9.5,  7.5]),\n",
       " array([12.5, 10. , 10. ,  8. ]),\n",
       " array([13.5, 11. , 11. ,  9. ]),\n",
       " array([15. , 12.5, 12.5, 10.5]),\n",
       " array([10., 18., 18., 26.]),\n",
       " array([11. , 19. ,  8.5, 16.5]),\n",
       " array([12. ,  9.5,  9.5,  7.5]),\n",
       " array([13. , 10.5, 10.5,  8.5]),\n",
       " array([14. , 11.5, 11.5,  9.5]),\n",
       " array([15. , 12.5, 12.5, 10.5]),\n",
       " array([12.5,  9.5,  9.5,  7.5]),\n",
       " array([19. , 16.5, 10. ,  7.5]),\n",
       " array([26., 17., 17.,  9.]),\n",
       " array([33.5, 24.5, 24.5, 16.5]),\n",
       " array([41.5, 32.5, 32.5, 24.5]),\n",
       " array([50., 41., 41., 33.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([ 0., 20., 20., 20.]),\n",
       " array([0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_generator(5, state, action, transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# 5 agents; big\n",
    "# payoff matrix\n",
    "\n",
    "N = 5\n",
    "action = action_generator(N)\n",
    "print(len(action))\n",
    "state = state_generator(N)\n",
    "print(len(state))\n",
    "payoff = phi_generator(N, state, action, transition)\n",
    "print(len(payoff))\n",
    "payoff = -np.array(payoff)\n",
    "transition = transition_generator(state, action, N)\n",
    "\n",
    "nS = len(state)\n",
    "nA = len(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "def P_generator(N, action, state, transition, payoff):\n",
    "    P = dict()\n",
    "    nS = len(state)\n",
    "    print(nS)\n",
    "    nA = len(action)\n",
    "    for s in range(nS):\n",
    "        P[s] = {a : [] for a in range(nA)}\n",
    "        \n",
    "    a = 0\n",
    "    \n",
    "    for state in range(nS):\n",
    "        for a in range(nA):\n",
    "            tmp = []\n",
    "            prob = 1\n",
    "            snext = transition[state][a]\n",
    "            reward = payoff[state][a]\n",
    "            done = False\n",
    "            if snext == (nS-1):\n",
    "                done = True\n",
    "            # prob, next_state, reward, done\n",
    "            tmp.extend([(prob, int(snext), reward, done)])\n",
    "            P[state][a] = tmp\n",
    "\n",
    "    return P\n",
    "P = P_generator(N, action, state, transition, payoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(theta=0.0001, discount_factor=1.0):\n",
    "    policy_list = []\n",
    "    \n",
    "    \n",
    "    def one_step_lookahead(state, V):\n",
    "        A = np.zeros(nA)\n",
    "        for a in range(nA):\n",
    "            for prob, next_state, reward, done in P[state][a]:\n",
    "                A[a] += prob * (reward + discount_factor * V[next_state])\n",
    "        return A\n",
    "\n",
    "    V = np.zeros(nS)\n",
    "    iter = 0\n",
    "    dl = []\n",
    "    vl = []\n",
    "\n",
    "    for _ in range(10):\n",
    "        iter += 1\n",
    "        print(iter)\n",
    "        # Stopping condition\n",
    "        delta = 0\n",
    "        # Update each state...\n",
    "        for s in range(nS):\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10.\n",
    "            V[s] = best_action_value\n",
    "\n",
    "        vl.append(V.copy())\n",
    "        dl.append(delta)\n",
    "\n",
    "        # Check if we can stop\n",
    "        print(\"debug-> iter={}, delta={:.5f}, V={}\".format(iter, delta, V))\n",
    "#         if delta < theta:\n",
    "#             break\n",
    "        # Create a deterministic policy using the optimal value function\n",
    "        policy_iter = np.zeros([nS, nA])\n",
    "        for s in range(nS):\n",
    "            # One step lookahead to find the best action for this state\n",
    "            A = one_step_lookahead(s, V)\n",
    "            # pdb.set_trace()\n",
    "            policy_t = A\n",
    "            best_action = np.argmax(A)\n",
    "            # Always take the best action\n",
    "            # policy_iter[s, best_action] = 1.0\n",
    "            # soft policy\n",
    "            policy_iter[s, :] = policy_t # record action values\n",
    "        policy_list.append(policy_iter)\n",
    "        # print(\"policy\", policy_iter)\n",
    "\n",
    "    # Create a deterministic policy using the optimal value function\n",
    "    policy = np.zeros([nS, nA])\n",
    "    for s in range(nS):\n",
    "        # One step lookahead to find the best action for this state\n",
    "        A = one_step_lookahead(s, V)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        policy[s, best_action] = 1.0\n",
    "\n",
    "    return policy, V, dl, vl, policy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "debug-> iter=1, delta=15.00000, V=[-15.   -6.5  -5.   -4.5  -4.5  -5.5  -7.5 -10.   -8.5  -7.5  -7.   -7.\n",
      "  -7.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "2\n",
      "debug-> iter=2, delta=9.00000, V=[-20.5 -13.5 -12.  -11.5 -12.  -13.  -15.  -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "3\n",
      "debug-> iter=3, delta=9.00000, V=[-28.  -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "4\n",
      "debug-> iter=4, delta=8.50000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "5\n",
      "debug-> iter=5, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "6\n",
      "debug-> iter=6, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "7\n",
      "debug-> iter=7, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "8\n",
      "debug-> iter=8, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "9\n",
      "debug-> iter=9, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n",
      "10\n",
      "debug-> iter=10, delta=0.00000, V=[-36.5 -21.  -20.  -20.  -20.5 -22.  -23.5 -16.5 -14.  -13.5 -14.5 -15.5\n",
      " -16.5  -6.5  -5.5  -6.   -7.5 -10.5 -15.    0.    0.    0.    0.    0.\n",
      "   0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "policy, V, dl, vl, policy_list = value_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### plot\n",
    "\n",
    "v1 = np.array(vl)\n",
    "x = np.arange(0, 10)\n",
    "mean_v = np.mean(v1,axis=1) # sum列；得到维度与行维度相同\n",
    "plt.plot(x, mean_v, linewidth=1.8)\n",
    "plt.scatter(x, mean_v)\n",
    "plt.xlabel('#Iter')\n",
    "plt.ylabel('sum of $V_k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
